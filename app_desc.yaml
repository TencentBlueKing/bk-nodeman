spec_version: 2
app_version: "{{APP_VERSION}}"
app:
    region: default
    bk_app_code: "bk_nodeman"
    bk_app_name: "节点管理"
    market:
        category: 运维工具
        introduction: 通过节点管理，可以对蓝鲸体系中的gse agent进行管理，包括状态查询、版本更新、配置管理、健康检查、进程管理等。
        display_options:
            width: 1300
            height: 720
            is_win_maximize: True
            open_mode: "new_tab"
modules:
    default:
        is_default: True
        source_dir: src
        language: Python
        services:
            - name: mysql
            - name: bkrepo
        env_variables:
            - key: BKAPP_IS_V3_CONTAINER
              value: "True"
              description: 是否运行在V3容器版本
            - key: BKAPP_USE_IAM
              value: "True"
              description: 是否使用权限中心
            - key: PIP_VERSION
              value: "20.2.3"
              description: 固化pip版本
            - key: STORAGE_TYPE
              value: "BLUEKING_ARTIFACTORY"
              description: 存储类型
            - key: GSE_ENABLE_SVR_DISCOVERY
              value: "True"
              description: 是否启用 gse svr 服务发现，启用后，默认接入点会通过zk的方式，自动更新 gse svr 信息
        svc_discovery:
            bk_saas:
                - bk_app_code: "bk_iam"
                - bk_app_code: "bk_nodeman"
                  module_name: "backend"
                - bk_app_code: "bk_nodeman"
                  module_name: "default"
        processes:
            web:
                command: gunicorn wsgi -w 4 -b :$PORT --access-logfile - --error-logfile - --access-logformat '[%(h)s] %({request_id}i)s %(u)s %(t)s "%(r)s" %(s)s %(D)s %(b)s "%(f)s" "%(a)s"'
                plan: 4C2G5R
                replicas: 5

    backend:
        is_default: False
        source_dir: src
        language: Python
        services:
            - name: rabbitmq
            - name: redis
            - name: bkrepo
              shared_from: default
            - name: mysql
              shared_from: default
        env_variables:
            - key: BKAPP_IS_V3_CONTAINER
              value: "True"
              description: 是否运行在V3容器版本
            - key: BKAPP_USE_IAM
              value: "True"
              description: 是否使用权限中心
            - key: REDIS_MODE
              value: "standalone"
              description: 后台配置的Redis模式
            - key: BACKEND_CONFIG
              value: "True"
              description: 是否启用后台配置，用于同一份代码区分SaaS和后台的差异化配置
            - key: PIP_VERSION
              value: "20.2.3"
              description: 固化pip版本
            - key: BKAPP_IS_PAAS_DEPLOY
              value: "True"
              description: 是否基于PaaS部署
            - key: STORAGE_TYPE
              value: "BLUEKING_ARTIFACTORY"
              description: 存储类型
            - key: GSE_ENABLE_SVR_DISCOVERY
              value: "True"
              description: 是否启用 gse svr 服务发现，启用后，默认接入点会通过zk的方式，自动更新gse svr信息
        svc_discovery:
            bk_saas:
                - bk_app_code: "bk_iam"
                - bk_app_code: "bk_nodeman"
                  module_name: "backend"
                - bk_app_code: "bk_nodeman"
                  module_name: "default"
        processes:
            backend-web:
                command: gunicorn --timeout 300 -w 8 -b :$PORT -k gevent wsgi:application --access-logfile - --error-logfile - --access-logformat '[%(h)s] %({request_id}i)s %(u)s %(t)s "%(r)s" %(s)s %(D)s %(b)s "%(f)s" "%(a)s"'
                plan: 4C2G5R
                replicas: 1
            celery-beat:
                command: celery -A apps.backend beat -l info
                plan: 4C2G5R
                replicas: 1
            dworker:
                command: celery -A apps.backend worker -Q default -n default@%h -P threads -c 64 --maxtasksperchild=50 -O fair --time-limit=1800
                plan: 4C2G5R
                replicas: 1
            bworker:
                command: celery -A apps.backend worker -Q backend -n bworker@%h -P threads -c 64 --maxtasksperchild=50 -O fair --time-limit=1800
                plan: 4C2G5R
                replicas: 1
            baworker:
                command: celery -A apps.backend worker -Q backend_additional_task -n baworker@%h -P threads -c 64 -O fair --time-limit=1800 --maxtasksperchild=50
                plan: 4C2G5R
                replicas: 1
            pworker:
                command: celery -A apps.backend worker -Q pipeline,pipeline_priority -n pipeline_worker@%h -P threads -c 100 --maxtasksperchild=50 -O fair --time-limit=1800
                plan: 4C2G5R
                replicas: 1
            psworker:
                # -P eventlet -> threads
                # eventlet 会导致报错 -> django.db.utils.DatabaseError: DatabaseWrapper objects created in a thread can only be used in that same thread. The object with alias 'default' was created in thread id 140032074089736 and this is thread id 140031737889904.
                # 该问题目前的解决方式是不使用 eventlet
                # 参考 -> https://github.com/celery/celery/issues/5924
                # 参考 -> https://github.com/intelowlproject/IntelOwl/issues/379
                command: celery -A apps.backend worker -Q service_schedule,service_schedule_priority -n schedule_worker@%h -P threads -c 100 --maxtasksperchild=50 -O fair --time-limit=1800
                plan: 4C2G5R
                replicas: 1
            paworker:
                command: celery -A apps.backend worker -Q pipeline_additional_task,pipeline_additional_task_priority -n common_worker@%h -l info -P threads -c 32 --maxtasksperchild=50 -O fair --time-limit=1800
                plan: 4C2G5R
                replicas: 1
            sync-host:
                command: python manage.py sync_host_event
                plan: 4C2G5R
                replicas: 1
            sync-host-re:
                command: python manage.py sync_host_relation_event
                plan: 4C2G5R
                replicas: 1
            sync-host-pr:
                command: python manage.py sync_process_event
                plan: 4C2G5R
                replicas: 1
            resource-w:
                command: python manage.py apply_resource_watched_events
                plan: 4C2G5R
                replicas: 1
